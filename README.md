# Attacks-and-Defenses-in-Federated-Learning
## 攻击算法
### 非定向攻击
* [《Data Poisoning Attacks Against Federated Learning Systems》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Data%20Poisoning%20Attacks%20Against%20FederatedLearning%20Systems.pdf)
* [《Towards poisoning of deep learning algorithms with backgradient optimization》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Towards%20poisoning%20of%20deep%20learning%20algorithms%20with%20backgradient%20optimization.pdf)
* [《Poison frogs! targeted clean-label poisoning attacks on neural networks》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Poison%20frogs!%20targeted%20clean-label%20poisoning%20attacks%20on%20neural%20networks.pdf)
* [《Poisoning attacks against support vector machines》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Poisoning%20attacks%20against%20support%20vector%20machines.pdf)
* [《Label sanitization against label flipping poisoning attacks》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Label%20sanitization%20against%20label%20flipping%20poisoning%20attacks.pdf)
* [《Poisoning attack in federated learning using generative adversarial nets》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Poisoning%20attack%20in%20federated%20learning%20using%20generative%20adversarial%20nets.pdf)
* [《Analyzing federated learning through an adversarial lens》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Analyzing%20federated%20learning%20through%20an%20adversarial%20lens.pdf)
* [《The hidden vulnerability of distributed learning in byzantium》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/The%20hidden%20vulnerability%20of%20distributed%20learning%20in%20byzantium.pdf)
* [《Local model poisoning attacks to Byzantine-robust federated learning》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Local%20model%20poisoning%20attacks%20to%20Byzantine-robust%20federated%20learning.pdf)
### 后门攻击
* [《DBA: Distributed Backdoor Attacks against Federated Learning》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/DBA-%20Distributed%20Backdoor%20Aattacks%20against%20Federated%20Learning.pdf)
* [《How to backdoor federated learning》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/How%20To%20Backdoor%20Federated%20Learning.pdf)
* [《Badnets: Identifying vulnerabilities in the machine learning model supply chain》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/BadNets%EF%BC%9AIdentifying%20Vulnerabilities%20in%20the%20Machine%20Learning%20Model%20Supply%20Chain.pdf)
* [《A little is enough: Circumventing defenses for distributed learning》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/A%20little%20is%20enough%EF%BC%9ACircumventing%20defenses%20for%20distributed%20learning.pdf)
* [《Can you really backdoor federated learning?》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Can%20You%20Really%20Backdoor%20Federated%20Learning.pdf)
* [《Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Targeted%20Backdoor%20Attacks%20on%20Deep%20Learning%20Systems%20Using%20Data%20Poisoning.pdf)
* [《Trojaning Attack on Neural Networks》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Trojaning%20Attack%20on%20Neural%20Networks.pdf)
### Free rider attack
* [《Free-rider Attacks on Model Aggregation in Federated Learning》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Free-rider%20Attacks%20on%20Model%20Aggregation%20in%20Federated%20Learning.pdf)
### 隐私窃取
* [《Deep models under the GAN: information leakage from collaborative deep learning》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Deep%20models%20under%20the%20GAN_%20information%20leakage%20from%20collaborative%20deep%20learning.pdf)
* [《Inverting Gradients – How easy is it to break privacy in federated learning?》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Inverting%20Gradients%20%E2%80%93%20How%20easy%20is%20it%20to%20break%20privacy%20in%20federated%20learning_%2C.pdf)
### 推理攻击

## 防御算法
### 数据清洗和网络修剪
* [《Fine-pruning: Defending against backdooring attacks on deep neural networks》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Fine-pruning_%20Defending%20against%20backdooring%20attacks%20on%20deep%20neural%20networks.pdf)
* [《Using trusted data to train deep networks on labels corrupted by severe noise》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Using%20trusted%20data%20to%20train%20deep%20networks%20on%20labels%20corrupted%20by%20severe%20noise.pdf)
* [《Draco: Byzantine-resilient distributed training via redundant gradients》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Draco_%20Byzantine-resilient%20distributed%20training%20via%20redundant%20gradients.pdf)
### 审计/detection
* [《Mitigating sybils in federated learning poisoning》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Mitigating%20sybils%20in%20federated%20learning%20poisoning.pdf)
* [《Understanding distributed poisoning attack in federated learning》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Understanding%20distributed%20poisoning%20attack%20in%20federated%20learning.pdf)
* [《Auror: Defending against poisoning attacks in collaborative deep learning systems》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/AUROR%20Defending%20Against%20Poisoning%20Attacks%20in%20Collaborative%20Deep%20Learning%20Systems.pdf)
* [《Abnormal client behavior detection in federated learning》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Abnormal%20client%20behavior%20detection%20in%20federated%20learning.pdf)
* [《Detecting and mitigating poisoning attacks in federated learning using generative adversarial networks》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Detecting%20and%20mitigating%20poisoning%20attacks%20in%20federated%20learning%20using%20generative%20adversarial%20networks.pdf)
* [《Shielding Collaborative Learning: Mitigating Poisoning Attacks through Client-Side Detection》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Shielding%20Collaborative%20Learning_%20Mitigating%20Poisoning%20Attacks%20through%20Client-Side%20Detection.pdf)
* [《PDGAN: A Novel Poisoning Defense Method in Federated Learning Using Generative Adversarial Network》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/PDGAN_%20A%20Novel%20Poisoning%20Defense%20Method%20in%20Federated%20Learning%20Using%20Generative%20Adversarial%20Network.pdf)
* [《Spectral signatures in backdoor attacks》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Spectral%20signatures%20in%20backdoor%20attacks.pdf)
* [《Neural cleanse: Identifying and mitigating backdoor attacks in neural networks》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Neural%20cleanse_Identifying%20and%20mitigating%20backdoor%20attacks%20in%20neural%20networks.pdf)
* [《Detecting backdoor attacks on deep neural networks by activation clustering》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Detecting%20backdoor%20attacks%20on%20deep%20neural%20networks%20by%20activation%20clustering.pdf)
* [《DeepInspect: A Black-box Trojan Detection and Mitigation Framework for Deep Neural Networks》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/DeepInspect_A%20Black-box%20Trojan%20Detection%20and%20Mitigation%20Framework%20for%20Deep%20Neural%20Networks.pdf)
* [《Backdoor attacks on federated meta-learning》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Backdoor%20attacks%20on%20federated%20meta-learning.pdf)
* [《Learning to Detect Malicious Clients for Robust Federated Learning》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Learning%20to%20Detect%20Malicious%20Clients%20for%20Robust%20Federated%20Learning.pdf)
#### 其中，利用了余弦相似度的：
* [《FLGUARD: Secure and Private Federated Learning》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/FLGUARD：%20Secure%20and%20Private%20Federated%20Learning.pdf)
* 
#### 其中，利用了聚类技术的：

### 鲁棒性优化及聚合
* [《Distributed statistical machine learning in adversarial settings: Byzantine gradient descent》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Distributed%20statistical%20machine%20learning%20in%20adversarial%20settings.pdf)
* [《Attack-Resistant Federated Learning with Residual-based Reweighting》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Attack-Resistant%20Federated%20Learning%20with%20Residual-based%20Reweighting.pdf)
*  [《Machine learning with adversaries: Byzantine tolerant gradient descent》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/NIPS-2017-machine-learning-with-adversaries-byzantine-tolerant-gradient-descent-Paper.pdf)
* [《Byzantine-robust distributed learning: Towards optimal statistical rates》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Byzantine-robust%20distributed%20learning.pdf)
* [《RSA: Byzantine-robust stochastic aggregation methods for distributed learning from heterogeneous datasets》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Byzantine-robust%20stochastic%20aggregation%20methods%20for%20distributed%20learning%20from%20heterogeneous%20datasets.pdf)
* [《Federated variance-reduced stochastic gradient descent with robustness to byzantine attacks》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Federated%20variance-reduced%20stochastic%20gradient%20descent%20with%20robustness%20to%20byzantine%20attacks.pdf)
* [《Asynchronous Byzantine machine learning (the case of SGD)》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Asynchronous%20Byzantine%20machine%20learning.pdf)
* [《Byzantine-Resilient High-Dimensional Federated Learning》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Byzantine-Resilient%20High-Dimensional%20Federated%20Learning%2C.pdf)
* [《BASGD: Buffered Asynchronous SGD for Byzantine Learning》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Buffered%20Asynchronous%20SGD%20for%20Byzantine%20Learning.pdf)
* [《Robust aggregation for federated learning》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Robust%20Aggregation%20for%20Federated%20Learning.pdf)
* [《Byzantine-robust federated machine learning through adaptive model averaging》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Byzantine-Robust%20Federated%20Learning%20through%20Adaptive%20Model%20Averaging.pdf)
* [《Federated optimization: Distributed machine learning for on-device intelligence》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Federated%20optimization%E2%80%94%E2%80%94%20Distributed%20machine%20learning%20for%20on-device%20intelligence.pdf)
* [《Co-op: Cooperative machine learning from mobile devices》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/CO-OP%E2%80%94%E2%80%94COOPERATIVE%20MACHINE%20LEARNING.pdf)
### 框架设计
* [《Biscotti: A ledger for private and securepeer-to-peer machine learning》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Biscotti%E2%80%94%E2%80%94%20A%20Ledger%20for%20Private%20and%20Secure%20Peer-to-Peer%20Machine%20Learningpdf.pdf)
* [《BOHB: Robust and efficient hyperparameter optimization at scale》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/BOHB%E2%80%94%E2%80%94%20Robust%20and%20efficient%20hyperparameter%20optimization%20at%20scale.pdf)
* [《Dynamic Federated Learning Model for Identifying Adversarial Clients》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Dynamic%20Federated%20Learning%20Model%20for%20Identifying.pdf)
* [《Bayesian nonparametric federated learning of neural networks》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Bayesian%20Nonparametric%20Federated%20Learning%20of%20Neural%20Networks.pdf)
* [《Exploiting Defenses against GAN-Based Feature Inference Attacks in Federated Learning》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/Exploiting%20Defenses%20against%20GAN-Based%20Feature%20Inference.pdf)
* [《Rappor: Randomized aggregatable privacypreserving ordinal response》](https://github.com/jgshu/Attacks-and-Defenses-in-Federated-Learning/blob/main/%E6%96%87%E7%8C%AE/RAPPOR%E2%80%94%E2%80%94Randomized%20Aggregatable%20Privacy-Preserving.pdf)
