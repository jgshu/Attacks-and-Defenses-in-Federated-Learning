# Attacks-and-Defenses-in-Federated-Learning
## 攻击算法
### 非定向攻击
* [《Data Poisoning Attacks Against Federated Learning Systems》](/文献/Data Poisoning Attacks Against Federated Learning Systems.pdf)
* 《Towards poisoning of deep learning algorithms with backgradient optimization》
* 《Poison frogs! targeted clean-label poisoning attacks on neural networks》
* 《Poisoning attacks against support vector machines》
* 《Label sanitization against label flipping poisoning attacks》
* 《Poisoning attack in federated learning using generative adversarial nets》
* 《Analyzing federated learning through an adversarial lens》
* 《The hidden vulnerability of distributed learning in byzantium》
* 《Local model poisoning attacks to Byzantine-robust federated learning》
### 后门攻击
* 《DBA: Distributed Backdoor Attacks against Federated Learning》
* 《How to backdoor federated learning》
* 《Badnets: Identifying vulnerabilities in the machinelearning model supply chain》
* 《A little is enough: Circumventing defenses for distributed learning》
* 《Can you really backdoor federated learning?》
* 《Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning》
* 《Trojaning Attack on Neural Networks》
### Free rider attack
* 《Free-rider Attacks on Model Aggregation in Federated Learning》
### 推理攻击

## 防御算法
### 数据清洗和网络修剪
* 《Fine-pruning: Defending against backdooring attacks on deep neural networks》
* 《Using trusted data to train deep networks on labels corrupted by severe noise》
* 《Draco: Byzantine-resilient distributed training via redundant gradients》
### 审计/detection
* 《Mitigating sybils in federated learning poisoning》
* 《Understanding distributed poisoning attack in federated learning》
* 《Auror: Defending against poisoning attacks in collaborative deep learning systems》
* 《Abnormal client behavior detection in federated learning》
* 《Detecting and mitigating poisoning attacks in federated learning using generative adversarial networks》
* 《Shielding Collaborative Learning: Mitigating Poisoning Attacks through Client-Side Detection》
* 《PDGAN: A Novel Poisoning Defense Method in Federated Learning Using Generative Adversarial Network》
* 《Spectral signatures in backdoor attacks》
* 《Neural cleanse: Identifying and mitigating backdoor attacks in neural networks》
* 《Detecting backdoor attacks on deep neural networks by activation clustering》
* 《DeepInspect: A Black-box Trojan Detection and Mitigation Framework for Deep Neural Networks》
* 《Backdoor attacks on federated meta-learning》
* 《Learning to Detect Malicious Clients for Robust Federated Learning》
#### 其中，利用了余弦相似度的：
* 《FLGUARD: Secure and Private Federated Learning》
* 
#### 其中，利用了聚类技术的：

### 鲁棒性优化及聚合
* 《Distributed statistical machine learning in adversarial settings: Byzantine gradient descent》
* 《Attack-Resistant Federated Learning with Residual-based Reweighting》
* 《Machine learning with adversaries: Byzantine tolerant gradient descent》
* 《Byzantine-robust distributed learning: Towards optimal statistical rates》
* 《RSA: Byzantine-robust stochastic aggregation methods for distributed learning from heterogeneous datasets》
* 《Federated variance-reduced stochastic gradient descent with robustness to byzantine attacks》
* 《Asynchronous Byzantine machine learning (the case of SGD)》
* 《Byzantine-Resilient High-Dimensional Federated Learning》
* 《BASGD: Buffered Asynchronous SGD for Byzantine Learning》
* 《Robust aggregation for federated learning》
* 《Byzantine-robust federated machine learning through adaptive model averaging》
* 《Federated optimization: Distributed machine learning for on-device intelligence》
* 《Co-op: Cooperative machine learning from mobile devices》
### 框架设计
* 《Biscotti: A ledger for private and securepeer-to-peer machine learning》
* 《BOHB: Robust and efficient hyperparameter optimization at scale》
* 《Dynamic Federated Learning Model for Identifying Adversarial Clients》
* 《Bayesian nonparametric federated learning of neural networks》
* 《Exploiting Defenses against GAN-Based Feature Inference Attacks in Federated Learning》
* 《Rappor: Randomized aggregatable privacypreserving ordinal response》
